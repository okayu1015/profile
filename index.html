<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->

  <title>Yui Oka - 岡佑依</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yui Oka</name><br>
                en / <a href="index_ja.html">ja</a>
              </p>
              <p>I am a Researcher at NTT Human Informatics Laboratories, NTT Corporation. At NTT, I develop both foundational theory and practical methods in Natural Language Processing. My research spans analytical studies of positional encoding, position interpolation, and extrapolation in large language models (LLMs). I have published in peer-reviewed venues and presented at leading international conferences such as ICLR and EMNLP, contributing to the broader NLP research community. In addition, I am involved in the development of context extension techniques for LLMs, leveraging my expertise in positional encoding and long-context modeling.
              </p>
              <p style="text-align:center">
                <a href="mailto:yui.oka.vf@hco.ntt.co.jp">Email(old)</a> &nbsp/&nbsp
                <a href="mailto:yui.oka@ntt.com">Email(current)</a> &nbsp/&nbsp
                <a href="https://github.com/okayu1015">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/33214171.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/33214171.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


  <heading>Paper</heading>
		<h3><u>Journal</u></h3>
		<font size="3"><strong>Length-constrained Neural Machine Translation using Length Prediction and Perturbation into Length-aware Positional Encoding</strong></font>
              <br>
	      Yui Oka, Katsuhito Sudoh, Satoshi Nakamura<br>
	      Journal of Natural Language Processing, 2021<br>
        [<a href="https://www.jstage.jst.go.jp/article/jnlp/28/3/28_778/_article/-char/en/">paper</a>]<br>
		<p></p>

		<h3><u>Conference</u></h3>
		<font size="3"><strong>Probing Rotary Position Embeddings through Frequency Entropy</strong></font>
              <br>
              Yui Oka, Kentaro Hanafusa, Taku Hasegawa, Kyosuke Nishida, Kuniko Saito<br>
              The Fourteenth International Conference on Learning Representations (ICLR 2026)<br>
		<p></p>

		<font size="3"><strong>How Base Frequency Shapes RoPE: An Analytical Study of Frequency-Band Formation</strong></font>
              <br>
              Yui Oka, Itsumi Saito, Kyosuke Nishida, Kuniko Saito<br>
              The Fourteenth International Conference on Learning Representations (ICLR 2026)<br>
		<p></p>
		
		<font size="3"><strong>Wavelet-based Positional Representation for Long Context</strong></font>
              <br>
              Yui Oka, Taku Hasegawa, Kyosuke Nishida, Kuniko Saito<br>
              The Thirteenth International Conference on Learning Representations (ICLR 2025)<br>
		<p></p>
	      
		<font size="3"><strong>Implicit Sense-labeled Connective Recognition as Text Generation</strong></font>
              <br>
              Yui Oka, Tsutomu Hirao<br>
              Findings of the Association for Computational Linguistics: EMNLP 2023 (EMNLP2023 findings)<br>
              [<a href="https://aclanthology.org/2023.findings-emnlp.487/">paper</a>]<br>
		<p></p>

		<font size="3"><strong>NT5 at WMT 2022 General Translation Task</strong></font>
              <br>
              Makoto Morishita*, Keito Kudo*, Yui Oka*, Katsuki Chousa*, Shun Kiyono, Sho Takase, Jun Suzuki (* Equal contribution)<br>
              Proceedings of the Seventh Conference on Machine Translation (WMT 2022)<br>
        [<a href="https://aclanthology.org/2022.wmt-1.25/">paper</a>]<br>
		<p></p>

		<font size="3"><strong>Simultaneous Speech-to-speech Translation System with Transformer-based Incremental ASR, MT, and TTS</strong></font>
              <br>
              Ryo Fukuda, Sashi Novitasari, Yui Oka, Yasumasa Kano, Yuki Yano, Yuka Ko, Hirotaka Tokuyama, Kosuke Doi, Tomoya Yanagita, Sakriani Sakti, Katsuhito Sudoh, Satoshi Nakamura<br>
              24th Conference of the Oriental COCOSDA International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques (O-COCOSDA 2021)<br>
        [<a href="https://ieeexplore.ieee.org/document/9660477">paper</a>] *Best Student Paper Award<br>
		<p></p>

		<font size="3"><strong>NAIST English-to-Japanese Simultaneous Translation System for IWSLT 2021 Simultaneous Text-to-text Task </strong></font>
              <br>
        Ryo Fukuda, Yui Oka, Yasumasa Kano, Yuki Yano, Yuka Ko, Hirotaka Tokuyama, Kosuke Doi, Sakriani Sakti, Katsuhito Sudoh, Satoshi Nakamura<br>
        Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021)<br>
        [<a href="https://aclanthology.org/2021.iwslt-1.3/">paper</a>]<br>
        <p></p>

		<font size="3"><strong>Using Perturbed Length-aware Positional Encoding for Non-autoregressive Neural Machine Translation </strong></font>
              <br>
	      Yui Oka, Katsuhito Sudoh, Satoshi Nakamura<br>
	      Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop (ACL-IJCNLP 2021 SRW)<br>
        [<a href="https://arxiv.org/abs/2107.13689">paper</a>] <br>
        <p></p>

		<font size="3"><strong>Incorporating Noisy Length Constraints into Transformer with Length-aware Positional Encodings</strong></font>
              <br>
	      Yui Oka, Katsuki Chousa, Katsuhito Sudoh, Satoshi Nakamura<br>
	      Proceedings of the 28th International Conference on Computational Linguistics (COLING 2020)<br>
        [<a href="https://aclanthology.org/2020.coling-main.319/">paper</a>]<br>
		<p></p>

    <br><br>
    <!--<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle"> -->
        <heading>Academic History</heading>
        <p></p>
        <font size="3"><strong>Master of Engineering</strong></font>
        <br>
        Apr 2019 - Mar 2021 <br>
        NARA Institute of Science and Technology(NAIST), Japan<br>
        <a href="https://ahcweb01.naist.jp/en/">Augmented Human Communication Laboratory</a><br>
        <p></p>
        <font size="3"><strong>Bachelor of Engineering</strong></font>
        <br>
        Apr 2015 - Mar 2019<br>
        Ehime Univercity, Japan<br>
        <p></p>
        <br><br>
        <heading>Reviewer</heading>
		<p> The Fourteenth International Conference on Learning Representations (ICLR2026)<br></p>
		<p> The Thirteenth International Conference on Learning Representations (ICLR2025)<br></p>
        <p> The 62nd Annual Meeting of the Association for Computational Linguistics (ACL2024)<br></p>
        <p> The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)<br></p>
        <p> The 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP2023)<br></p>
        <p> The 29th International Conference on Computational Linguistics (COLING2022)<br></p>
        <br>
        <br><br>

        <!--
        <heading>Other</heading>
	      <h3>Intern</h3>
              <p>Jan 2020 - Feb 2020 : Research Intern, NTT Communication Science Laboratories Innovative Communication Laboratory
              </p>
	      <h3>Development</h3>
	      <p>System Trade Bot ; Bitcoin automatic trading system using machine learning-->
		</p>

      </td>
    </tr>
  </tbody></table>
  
  <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle"> -->



	      
            </td>
          </tr>
        </tbody></table>
	
      </td>
    </tr>
  </table>
</body>

</html>
